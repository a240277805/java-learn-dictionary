# ELK 安装 
流程  [栗子](https://blog.csdn.net/weixin_38098312/article/details/80181415)
![avatar](https://operimgci.zhidaohulian.com/test/image/2019-08-29/531be1f901294a979b9d0c4811761a0b.png)

![avatar](https://img2018.cnblogs.com/blog/130857/201812/130857-20181203122611122-2121636116.png)


## 1. elastic search
es 启动需要切换用户 ，所以我本地没启用的测试环境的。

es  端口号 9200 
es-head 端口9100 用来监控
## 2. logstash   用来数据采集 加上数据格式转化

 采集性能上存在问题 ，所以一般采用 beats 采集，或者是用其他采集组件 比如 fluence?

 数据来源可以使 kafka ,文件 ,beats ，标准输入 等

 还可以自己编码 自定义 tag ,根据tag 发送到不同的es,或者先发送到 kafka ，再用kafka 发到 logstash ，logstash 再发到 es;

 发到es 可匹配 模板，es 有自带的 logstash 模板

 ### 从每台应用服务器运行Logstash进程并将数据直接发送到Elasticsearch里，显然不是第一选择，原因

 有三：第一，过多的客户端连接对Elasticsearch是一种额外的压力；第二，网络抖动会影响到Logstash进程，进而影响生产应用；第三，运维人员未必愿意在生产服务器上部署Java，或者让Logstash跟业务代码争夺Java资源。所以，在实际运用中，Logstash进程会被分为两个不同的角色。运行在应用服务器上的尽量减轻运行压力，只做读取和转发，这个角色叫做Shipper；运行在独立服务器上的完成数据解析处理，负责写入Elasticsearch的角色，叫Indexer。

### logstash 配置
参见  ../markdown/otherSource/logstash.conf

通过filebeats 写入 logstash

默认在 message ，需要将message 拆分成分词;

在filter 中定义

用了四种方式 

* mutate {split}  性能最好，最推荐使用的方式
* ruby { code=>}   编写 ruby 脚本进行分词
* json{} 将 json字符串自动分词，会有类型问题（target 必须是 obj）
* mutate {convert} 类型转换  原因:  想用es 的wildcard 进行模糊搜索，这要求映射的字段必须是string



output 定义 输出 

* 可以有多个
* index 自动创建索引，按天索引（再再kibana做聚合）
* 还可以定义自己写的映射，指定映射文件，这里没有使用





### source CODE
![avator](../imgSource/logstashSourceCode.png)
## 5.xpack  警告监控  好像是自带


## 4.beats 轻量级组件 数据采集 (filebeats ,metricbeat) 收集文件日志 收集系统日志
 配置 正则 匹配相关文件夹，就可以收集 ，还要配置要发送的机器
 采用 channel 管道的形式 采集数据 性能比较好。

## 3. kibana

## 参考
* *****[你头疼的ELK难题，本文几乎都解决了](https://zhuanlan.zhihu.com/p/270174202)

