# 服务架构
## 进化 
### 微服务
### kubernetes
### 云原生
云原生主要包括四个部分:

- 微服务
- 容器
- 持续集成和交付
- DevOps


### Service mesh 
![avatar](https://upload-images.jianshu.io/upload_images/3144413-37463a2c78d63d22.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/1170/format/webp)
Sevice Mesh 是云原生下的微服务治理方案。
主机独立进程代理
，蚂蚁金服已经有了自己的一套完整的 Service Mesh 服务框架-- Sofa Mesh
![avatar](https://img2018.cnblogs.com/blog/1837087/201910/1837087-20191025182722274-240580979.png)
Istio 是目前最热的 Service Mesh 开源项目

Istio 主要分为两个部分：数据平面和控制平面。

#### 现状
目前Service Mesh的实现非常多，其实在Service Mesh概念被提出以前，国内有些公司已经实现了基于Proxy的类似Service Mesh的结构，如唯品会的OSP Local Proxy，以及新浪的WeiboMesh，这两款产品都是在服务治理框架上增加代理层来降级升级和多语言成本。在ServiceMesh出来之后，又有一些大型互联网企业紧密跟进，如华为的CSE Mesher、美团的OCTOMesh、蚂蚁的SOFA Mesh、阿里的Dubbo Mesh，以及Google、IBM、Lyft联合开发的Istio。
#### 开元产品
Service Mesh的开源产品比较多，有以数据平面为代表的Linkerd和Envoy，另外还有Istio、Conduit、Weibo Mesh、SOFA Mesh、Dubbo Mesh等。
#### Mixer
Mixer 同样是一个可拓展的模块，其负责遥感数据的采集以及集成了一些后端服务（BAAS），Sidecar 会不断向 Mixer 报告自己的流量情况， Mixer 对流量情况进行汇总，以可视化的形式展现，此外 Sidecar 可以调用 Mixer 提供的一些后端服务能力，例如鉴权、登录、日志等等， Mixer 通过适配器的方式对接各种后端服务。

ServiceMesh其实并不是什么新东西，本质就是上面提到的服务发现模式三~主机独立进程模式，这个模式很早就有公司在探索和实践，但是一直没有普遍流行起来，说明这个模式也是存在落地挑战的。从表面上看，模式三是模式一和模式二的折中，同时解决了模式一和模式二存在的问题，但是在每个主机上独立部署一个代理进程，是有很大运维管理开销的，一方面是规模化部署的问题(考虑服务很多，机器也很多的场景)；另一方面是如何监控治理的问题，代理挂了怎么办？你的团队是否具备自动化运维和监控的能力？另外开发人员在服务调试的时候，会依赖于这个独立的代理，调试排错比较麻烦，这个问题怎么解决？

#### 缺点
1．性能Service Mesh方式的服务调用相比服务框架的直接调用增加了与Service Mesh中数据平面Sidecar的交互，虽然是本地网络通信，但性能上的损耗还是非常明显的，这也给Service Mesh大规模落地带来了困难。2．可用性Service Mesh通过单独的进程的方式来为应用程序提供服务，虽然它相对于应用程序来说比较透明，但其实也在整个服务调用链上增加了故障点，势必导致可用性问题。在落地的过程中，这是一个不小的挑战，因此需要对Service Mesh的整体设计提出更高的要求来保证服务的可用性。3．运维治理Service Mesh在运维治理上也存在一些难题，主要是三个方面的问题：首先是规模化部署的问题，特别是大型互联网公司，线上运行实例非常多，这些实例上都需要部署Sidecar；其次是如何监控治理的问题，如果Sidecar进程“挂了”怎么办？需要具备自动化运维和监控的能力；最后是开发人员在本地环境开发调试的时候，也需要依赖Sidecar，难道每个开发机器上也需要安装相关的Sidecar，并且在测试前先启动Sidecar进程？当然，如果类似Istio方案，借助K8S基础设施，那么前两个问题就不存在了，但目前还是存在很多公司没有完全使用K8S的情况。

## 参考

[微服务之-ServiceMesh](https://www.jianshu.com/p/27a742e349f7)